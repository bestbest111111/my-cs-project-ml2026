import os
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader, random_split
from torchvision import transforms
from PIL import Image
import cv2
import torch.optim as optim
from tqdm import tqdm
import matplotlib.pyplot as plt
import warnings

warnings.filterwarnings('ignore')

# è®¾ç½®è®¾å¤‡
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")

# ==================== é¢„å¤„ç†æ ¸å¿ƒå‡½æ•° ====================
def clahe_enhance(image_np, clip_limit=2.0, grid_size=(8, 8)):
    """CLAHEå¯¹æ¯”åº¦å¢å¼ºï¼ˆé€‚é…RGB/ç°åº¦å›¾åƒï¼‰"""
    if len(image_np.shape) == 2:
        gray = image_np
        clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=grid_size)
        enhanced_gray = clahe.apply(gray)
        return enhanced_gray
    elif len(image_np.shape) == 3 and image_np.shape[2] == 3:
        gray = cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY)
        clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=grid_size)
        enhanced_gray = clahe.apply(gray)
        enhanced_rgb = cv2.cvtColor(enhanced_gray, cv2.COLOR_GRAY2RGB)
        return enhanced_rgb
    else:
        return image_np

def gamma_correction(image_np, gamma=1.2):
    """Gammaæ ¡æ­£ï¼ˆæå‡/é™ä½å›¾åƒäº®åº¦ï¼‰"""
    image_normalized = image_np / 255.0
    corrected = np.power(image_normalized, gamma)
    corrected = (corrected * 255).astype(np.uint8)
    return corrected

def show_preprocess_example(image_path, save_path="preprocess_example.png"):
    """å±•ç¤ºé¢„å¤„ç†å‰åçš„å¯¹æ¯”æ•ˆæœ"""
    raw_image = Image.open(image_path).convert('RGB')
    raw_image = raw_image.resize((512, 512), Image.BILINEAR)
    raw_np = np.array(raw_image)
    
    clahe_np = clahe_enhance(raw_np)
    gamma_np = gamma_correction(clahe_np, gamma=1.2)
    
    print("\n" + "="*80)
    print("ğŸ“Š é¢„å¤„ç†å‰ååƒç´ å€¼ç»Ÿè®¡ï¼ˆç¤ºä¾‹ï¼‰")
    print("="*80)
    print(f"åŸå§‹å›¾åƒ - å‡å€¼: {np.mean(raw_np):.2f}, æ ‡å‡†å·®: {np.std(raw_np):.2f}, æœ€å°å€¼: {np.min(raw_np)}, æœ€å¤§å€¼: {np.max(raw_np)}")
    print(f"CLAHEå¢å¼ºå - å‡å€¼: {np.mean(clahe_np):.2f}, æ ‡å‡†å·®: {np.std(clahe_np):.2f}, æœ€å°å€¼: {np.min(clahe_np)}, æœ€å¤§å€¼: {np.max(clahe_np)}")
    print(f"Gammaæ ¡æ­£å - å‡å€¼: {np.mean(gamma_np):.2f}, æ ‡å‡†å·®: {np.std(gamma_np):.2f}, æœ€å°å€¼: {np.min(gamma_np)}, æœ€å¤§å€¼: {np.max(gamma_np)}")
    print("="*80)
    
    fig, axes = plt.subplots(1, 3, figsize=(18, 6))
    axes[0].imshow(raw_np)
    axes[0].set_title("åŸå§‹å›¾åƒ", fontsize=14)
    axes[0].axis('off')
    
    axes[1].imshow(clahe_np)
    axes[1].set_title("CLAHEå¯¹æ¯”åº¦å¢å¼º", fontsize=14)
    axes[1].axis('off')
    
    axes[2].imshow(gamma_np)
    axes[2].set_title("Gammaæ ¡æ­£ (Î³=1.2)", fontsize=14)
    axes[2].axis('off')
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"\nâœ… é¢„å¤„ç†å¯¹æ¯”å›¾å·²ä¿å­˜è‡³: {save_path}")
    print("="*80 + "\n")

# ==================== æ•°æ®åŠ è½½å’Œé¢„å¤„ç† ====================
class RetinaVesselDataset(Dataset):
    def __init__(self, image_dir, label_dir=None, transform=None, is_train=True, image_size=512):
        self.image_dir = image_dir
        self.label_dir = label_dir
        self.transform = transform
        self.is_train = is_train
        self.image_size = image_size

        self.image_files = []
        for file in sorted(os.listdir(image_dir)):
            if file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tif', '.gif')):
                self.image_files.append(file)

        print(f"æ‰¾åˆ° {len(self.image_files)} å¼ å›¾åƒ")
        
        if self.image_files and self.is_train:
            first_image_path = os.path.join(self.image_dir, self.image_files[0])
            show_preprocess_example(first_image_path)

    def __len__(self):
        return len(self.image_files)

    def __getitem__(self, idx):
        img_name = self.image_files[idx]
        img_path = os.path.join(self.image_dir, img_name)

        image = Image.open(img_path).convert('RGB')

        if self.is_train and self.label_dir:
            label_name = img_name
            label_path = os.path.join(self.label_dir, label_name)

            if os.path.exists(label_path):
                label = Image.open(label_path).convert('L')
            else:
                label = Image.new('L', image.size, 0)

            image = image.resize((self.image_size, self.image_size), Image.BILINEAR)
            label = label.resize((self.image_size, self.image_size), Image.NEAREST)

            image_np = np.array(image)
            label_np = np.array(label)

            # é¢„å¤„ç†
            image_np = clahe_enhance(image_np)
            image_np = gamma_correction(image_np, 1.2)
            
            label_np = (label_np > 128).astype(np.float32)

            image_tensor = transforms.ToTensor()(image_np)
            label_tensor = torch.from_numpy(label_np).unsqueeze(0)

            image_tensor = transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                                std=[0.229, 0.224, 0.225])(image_tensor)

            return image_tensor, label_tensor, img_name
        else:
            image = image.resize((self.image_size, self.image_size), Image.BILINEAR)
            image_np = np.array(image)
            
            image_np = clahe_enhance(image_np)
            image_np = gamma_correction(image_np, 1.2)
            
            image_tensor = transforms.ToTensor()(image_np)
            image_tensor = transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                                std=[0.229, 0.224, 0.225])(image_tensor)

            return image_tensor, img_name

    def get_image_id(self, idx):
        img_name = self.image_files[idx]
        return os.path.splitext(img_name)[0]

# ==================== UNetæ¨¡å‹å®šä¹‰ï¼ˆæ·»åŠ Dropoutï¼‰ ====================
class DoubleConv(nn.Module):
    """(å·ç§¯ => BN => ReLU => Dropout) * 2"""
    def __init__(self, in_channels, out_channels, dropout_rate=0.2):  # æ–°å¢dropout_rateå‚æ•°
        super().__init__()
        self.double_conv = nn.Sequential(
            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
            nn.Dropout2d(dropout_rate),  # 2D Dropoutï¼Œé’ˆå¯¹ç‰¹å¾å›¾
            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
            nn.Dropout2d(dropout_rate)   # ç¬¬äºŒå±‚å·ç§¯åä¹ŸåŠ Dropout
        )

    def forward(self, x):
        return self.double_conv(x)

class Down(nn.Module):
    """ä¸‹é‡‡æ ·ï¼šæœ€å¤§æ± åŒ– + DoubleConvï¼ˆå¸¦Dropoutï¼‰"""
    def __init__(self, in_channels, out_channels, dropout_rate=0.2):
        super().__init__()
        self.maxpool_conv = nn.Sequential(
            nn.MaxPool2d(2),
            DoubleConv(in_channels, out_channels, dropout_rate)  # ä¼ é€’dropoutå‚æ•°
        )

    def forward(self, x):
        return self.maxpool_conv(x)

class Up(nn.Module):
    """ä¸Šé‡‡æ · + è·³è·ƒè¿æ¥ï¼ˆå¸¦Dropoutï¼‰"""
    def __init__(self, in_channels, out_channels, bilinear=True, dropout_rate=0.2):
        super().__init__()
        if bilinear:
            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)
            self.conv = DoubleConv(in_channels, out_channels, dropout_rate)  # ä¼ é€’dropoutå‚æ•°
        else:
            self.up = nn.ConvTranspose2d(in_channels // 2, in_channels // 2, kernel_size=2, stride=2)
            self.conv = DoubleConv(in_channels, out_channels, dropout_rate)  # ä¼ é€’dropoutå‚æ•°

    def forward(self, x1, x2):
        x1 = self.up(x1)
        diffY = x2.size()[2] - x1.size()[2]
        diffX = x2.size()[3] - x1.size()[3]

        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,
                        diffY // 2, diffY - diffY // 2])
        x = torch.cat([x2, x1], dim=1)
        return self.conv(x)

class UNet(nn.Module):
    def __init__(self, n_channels=3, n_classes=1, bilinear=True, dropout_rate=0.2):  # æ–°å¢dropout_rateå‚æ•°
        super(UNet, self).__init__()
        self.n_channels = n_channels
        self.n_classes = n_classes
        self.bilinear = bilinear

        # ç¼–ç å™¨éƒ¨åˆ†ï¼ˆä¸‹é‡‡æ ·ï¼‰ï¼šé€å±‚è®¾ç½®Dropoutï¼ˆæµ…å±‚å°ï¼Œæ·±å±‚ç¨å¤§ï¼‰
        self.inc = DoubleConv(n_channels, 64, dropout_rate=0.1)  # è¾“å…¥å±‚Dropoutç¨å°ï¼ˆ0.1ï¼‰
        self.down1 = Down(64, 128, dropout_rate=0.15)            # ç¬¬ä¸€å±‚ä¸‹é‡‡æ ·ï¼ˆ0.15ï¼‰
        self.down2 = Down(128, 256, dropout_rate=0.2)            # ç¬¬äºŒå±‚ä¸‹é‡‡æ ·ï¼ˆ0.2ï¼‰
        self.down3 = Down(256, 512, dropout_rate=0.2)            # ç¬¬ä¸‰å±‚ä¸‹é‡‡æ ·ï¼ˆ0.2ï¼‰
        factor = 2 if bilinear else 1
        self.down4 = Down(512, 1024 // factor, dropout_rate=0.25)# æœ€æ·±å±‚Dropoutç¨å¤§ï¼ˆ0.25ï¼‰

        # è§£ç å™¨éƒ¨åˆ†ï¼ˆä¸Šé‡‡æ ·ï¼‰
        self.up1 = Up(1024, 512 // factor, bilinear, dropout_rate=0.25)
        self.up2 = Up(512, 256 // factor, bilinear, dropout_rate=0.2)
        self.up3 = Up(256, 128 // factor, bilinear, dropout_rate=0.15)
        self.up4 = Up(128, 64, bilinear, dropout_rate=0.1)

        self.outc = nn.Conv2d(64, n_classes, kernel_size=1)  # è¾“å‡ºå±‚ä¸åŠ Dropout

    def forward(self, x):
        x1 = self.inc(x)
        x2 = self.down1(x1)
        x3 = self.down2(x2)
        x4 = self.down3(x3)
        x5 = self.down4(x4)

        x = self.up1(x5, x4)
        x = self.up2(x, x3)
        x = self.up3(x, x2)
        x = self.up4(x, x1)
        logits = self.outc(x)
        return torch.sigmoid(logits)

# ==================== æŸå¤±å‡½æ•°å’Œè¯„ä»·æŒ‡æ ‡ ====================
class DiceLoss(nn.Module):
    def __init__(self, smooth=1e-6):
        super(DiceLoss, self).__init__()
        self.smooth = smooth

    def forward(self, predictions, targets):
        predictions = predictions.view(-1)
        targets = targets.view(-1)
        intersection = (predictions * targets).sum()
        dice = (2. * intersection + self.smooth) / (predictions.sum() + targets.sum() + self.smooth)
        return 1 - dice

def calculate_dice_coefficient(predictions, targets, smooth=1e-6):
    preds_binary = (predictions > 0.5).float()
    preds_flat = preds_binary.view(-1)
    targets_flat = targets.view(-1)
    intersection = (preds_flat * targets_flat).sum()
    union = preds_flat.sum() + targets_flat.sum()
    dice = (2. * intersection + smooth) / (union + smooth)
    return dice.item()

# ==================== è®­ç»ƒå‡½æ•° ====================
def train_epoch(model, train_loader, criterion, optimizer, device):
    model.train()
    epoch_loss = 0.0
    epoch_dice = 0.0
    total_batches = len(train_loader)

    for batch_idx, (images, masks, _) in enumerate(tqdm(train_loader, desc="Training", leave=False)):
        images = images.to(device)
        masks = masks.to(device)

        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, masks)
        dice = calculate_dice_coefficient(outputs, masks)
        
        loss.backward()
        optimizer.step()

        epoch_loss += loss.item()
        epoch_dice += dice

    avg_loss = epoch_loss / total_batches
    avg_dice = epoch_dice / total_batches
    return avg_loss, avg_dice

def validate_epoch(model, val_loader, criterion, device):
    model.eval()
    epoch_loss = 0.0
    epoch_dice = 0.0
    total_batches = len(val_loader)

    with torch.no_grad():
        for batch_idx, (images, masks, _) in enumerate(tqdm(val_loader, desc="Validation", leave=False)):
            images = images.to(device)
            masks = masks.to(device)

            outputs = model(images)
            loss = criterion(outputs, masks)
            dice = calculate_dice_coefficient(outputs, masks)

            epoch_loss += loss.item()
            epoch_dice += dice

    avg_loss = epoch_loss / total_batches
    avg_dice = epoch_dice / total_batches
    return avg_loss, avg_dice

def train_model(model, train_loader, val_loader, num_epochs=50, learning_rate=1e-4):
    print("å¼€å§‹è®­ç»ƒæ¨¡å‹ï¼ˆå¸¦Dropoutæ­£åˆ™åŒ–ï¼‰...")
    print("ä¿å­˜ç­–ç•¥ï¼šåŸºäºéªŒè¯é›†Diceç³»æ•°ï¼ˆè¶Šé«˜è¶Šå¥½ï¼‰")

    criterion = DiceLoss()
    optimizer = optim.Adam(model.parameters(), lr=learning_rate)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=5, factor=0.5)

    train_loss_history = []
    val_loss_history = []
    train_dice_history = []
    val_dice_history = []
    
    best_val_dice = 0.0
    best_epoch = 0
    best_model_state = None

    for epoch in range(num_epochs):
        print(f"\nEpoch {epoch + 1}/{num_epochs}")
        print("-" * 50)

        train_loss, train_dice = train_epoch(model, train_loader, criterion, optimizer, device)
        train_loss_history.append(train_loss)
        train_dice_history.append(train_dice)

        val_loss, val_dice = validate_epoch(model, val_loader, criterion, device)
        val_loss_history.append(val_loss)
        val_dice_history.append(val_dice)

        scheduler.step(val_dice)

        print(f"Train Loss: {train_loss:.4f} | Train Dice: {train_dice:.4f}")
        print(f"Val   Loss: {val_loss:.4f} | Val   Dice: {val_dice:.4f} (Best: {best_val_dice:.4f})")
        print(f"Current LR: {optimizer.param_groups[0]['lr']:.6f}")

        if val_dice > best_val_dice:
            best_val_dice = val_dice
            best_epoch = epoch + 1
            best_model_state = model.state_dict().copy()
            
            torch.save({
                'epoch': best_epoch,
                'model_state_dict': best_model_state,
                'best_val_dice': best_val_dice,
            }, 'best_model_by_dice.pth')
            
            print(f"âœ… æ›´æ–°æœ€ä½³æ¨¡å‹ | Epoch: {best_epoch} | Best Val Dice: {best_val_dice:.4f}")
        else:
            print(f"âŒ æœªæ›´æ–°æœ€ä½³æ¨¡å‹ | å½“å‰Val Dice: {val_dice:.4f} < å†å²æœ€ä½³: {best_val_dice:.4f}")

    if best_model_state is not None:
        model.load_state_dict(best_model_state)
        print(f"\n=====================================")
        print(f"è®­ç»ƒå®Œæˆï¼åŠ è½½æœ€ä½³æ¨¡å‹ï¼ˆåŸºäºéªŒè¯é›†Diceï¼‰")
        print(f"æœ€ä½³Epoch: {best_epoch}")
        print(f"æœ€ä½³Val Dice: {best_val_dice:.4f}")
        print(f"=====================================")

    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))
    
    ax1.plot(train_loss_history, label='Train Loss', marker='o', markersize=4)
    ax1.plot(val_loss_history, label='Val Loss', marker='s', markersize=4)
    if best_epoch > 0:
        ax1.scatter(best_epoch-1, val_loss_history[best_epoch-1], 
                   color='red', s=100, marker='*', label=f'Best Dice (Epoch {best_epoch})')
    ax1.set_xlabel('Epoch')
    ax1.set_ylabel('Loss')
    ax1.set_title('Training and Validation Loss')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    ax2.plot(train_dice_history, label='Train Dice', marker='o', markersize=4, color='green')
    ax2.plot(val_dice_history, label='Val Dice', marker='s', markersize=4, color='red')
    if best_epoch > 0:
        ax2.scatter(best_epoch-1, best_val_dice, 
                   color='red', s=100, marker='*', label=f'Best Dice ({best_val_dice:.4f})')
    ax2.set_xlabel('Epoch')
    ax2.set_ylabel('Dice Coefficient')
    ax2.set_title('Training and Validation Dice Coefficient')
    ax2.set_ylim(0, 1)
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('training_history.png', dpi=300, bbox_inches='tight')
    plt.close()

    history_df = pd.DataFrame({
        'epoch': range(1, num_epochs+1),
        'train_loss': train_loss_history,
        'val_loss': val_loss_history,
        'train_dice': train_dice_history,
        'val_dice': val_dice_history
    })
    history_df.to_csv('training_history.csv', index=False)
    print(f"\nè®­ç»ƒå†å²å·²ä¿å­˜åˆ°: training_history.csv")

    return model

# ==================== é¢„æµ‹å‡½æ•° ====================
def predict_test_set(model, test_loader, threshold=0.5):
    model.eval()
    predictions = {}

    with torch.no_grad():
        for images, img_names in tqdm(test_loader, desc="Predicting"):
            images = images.to(device)
            outputs = model(images)
            preds = (outputs > threshold).float()

            for i in range(len(img_names)):
                img_name = img_names[i]
                img_id = os.path.splitext(img_name)[0]
                pred_mask = preds[i, 0].cpu().numpy()
                pred_mask_resized = cv2.resize(pred_mask, (512, 512), interpolation=cv2.INTER_NEAREST)
                mask_uint8 = np.where(pred_mask_resized > 0.5, 0, 255).astype(np.uint8)
                predictions[img_id] = mask_uint8

    return predictions

# ==================== Run-lengthç¼–ç å‡½æ•° ====================
def rle_encode(mask):
    pixels = mask.flatten()
    dots = np.where(pixels == 0)[0]

    if len(dots) == 0:
        return ""

    run_lengths = []
    prev = -2
    for b in dots:
        if (b > prev + 1):
            run_lengths.extend((b + 1, 0))
        run_lengths[-1] += 1
        prev = b

    return ' '.join([str(r) for r in run_lengths])

# ==================== ä¿å­˜é¢„æµ‹ç»“æœ ====================
def save_predictions_to_csv(predictions, output_csv='submission.csv'):
    df = pd.DataFrame(columns=['Id', 'Predicted'])
    ids = []
    rle_strings = []

    try:
        sorted_ids = sorted(predictions.keys(), key=lambda x: int(x))
    except:
        sorted_ids = sorted(predictions.keys())

    for img_id in sorted_ids:
        mask = predictions[img_id]
        rle_str = rle_encode(mask)
        ids.append(img_id)
        rle_strings.append(rle_str)

    df['Id'] = ids
    df['Predicted'] = rle_strings
    df.to_csv(output_csv, index=False)
    print(f"é¢„æµ‹ç»“æœå·²ä¿å­˜åˆ°: {output_csv}")
    print(f"å…±ä¿å­˜äº† {len(df)} ä¸ªé¢„æµ‹ç»“æœ")

# ==================== ä¸»å‡½æ•° ====================
def main():
    print("=" * 60)
    print("è§†ç½‘è†œè¡€ç®¡åˆ†å‰² - è®­ç»ƒä¸é¢„æµ‹ï¼ˆé›†æˆCLAHE+Gamma+Dropoutï¼‰")
    print("=" * 60)

    # è®¾ç½®è·¯å¾„
    train_image_dir = '/kaggle/input/task-5-vesselsegmentation-2025/segmentation/train/image'
    train_label_dir = '/kaggle/input/task-5-vesselsegmentation-2025/segmentation/train/label'
    test_image_dir = '/kaggle/input/task-5-vesselsegmentation-2025/segmentation/test/image'
    output_csv = 'submission.csv'

    # æ£€æŸ¥è·¯å¾„
    print("\næ£€æŸ¥è·¯å¾„...")
    paths_to_check = [
        (train_image_dir, "è®­ç»ƒå›¾åƒ"),
        (train_label_dir, "è®­ç»ƒæ ‡ç­¾"),
        (test_image_dir, "æµ‹è¯•å›¾åƒ")
    ]

    all_paths_exist = True
    for path, desc in paths_to_check:
        if os.path.exists(path):
            print(f"âœ“ {desc}è·¯å¾„: {path}")
        else:
            print(f"âœ— {desc}è·¯å¾„ä¸å­˜åœ¨: {path}")
            all_paths_exist = False

    if not all_paths_exist:
        print("\nè­¦å‘Š: éƒ¨åˆ†è·¯å¾„ä¸å­˜åœ¨ï¼Œå°†ä½¿ç”¨å¤‡ç”¨è·¯å¾„...")
        train_image_dir = './train/image' if os.path.exists('./train/image') else train_image_dir
        train_label_dir = './train/label' if os.path.exists('./train/label') else train_label_dir
        test_image_dir = './test/image' if os.path.exists('./test/image') else test_image_dir

    # å‡†å¤‡æ•°æ®
    print("\n" + "=" * 60)
    print("ç¬¬1æ­¥ï¼šå‡†å¤‡æ•°æ®ï¼ˆé›†æˆCLAHE+Gammaé¢„å¤„ç†ï¼‰")
    print("=" * 60)

    train_dataset = RetinaVesselDataset(
        image_dir=train_image_dir,
        label_dir=train_label_dir,
        is_train=True,
        image_size=512
    )

    print(f"è®­ç»ƒé›†å¤§å°: {len(train_dataset)}")

    val_size = min(50, int(len(train_dataset) * 0.2))
    train_size = len(train_dataset) - val_size

    train_dataset, val_dataset = random_split(
        train_dataset,
        [train_size, val_size],
        generator=torch.Generator().manual_seed(42)
    )

    print(f"è®­ç»ƒé›†: {len(train_dataset)}, éªŒè¯é›†: {len(val_dataset)}")

    train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=2)
    val_loader = DataLoader(val_dataset, batch_size=2, shuffle=False, num_workers=2)

    # è®­ç»ƒæ¨¡å‹ï¼ˆåˆå§‹åŒ–å¸¦Dropoutçš„UNetï¼‰
    print("\n" + "=" * 60)
    print("ç¬¬2æ­¥ï¼šè®­ç»ƒæ¨¡å‹ï¼ˆå¸¦Dropoutæ­£åˆ™åŒ–ï¼‰")
    print("=" * 60)

    # åˆå§‹åŒ–æ¨¡å‹æ—¶æŒ‡å®šdropout_rateï¼ˆä¹Ÿå¯ä½¿ç”¨é»˜è®¤å€¼ï¼‰
    model = UNet(n_channels=3, n_classes=1, bilinear=True, dropout_rate=0.2)
    model = model.to(device)
    print(f"æ¨¡å‹å‚æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
    
    train_model(
        model=model,
        train_loader=train_loader,
        val_loader=val_loader,
        num_epochs=120,
        learning_rate=1e-3
    )

    # é¢„æµ‹
    print("\n" + "=" * 60)
    print("ç¬¬3æ­¥ï¼šå‡†å¤‡æµ‹è¯•æ•°æ®")
    print("=" * 60)

    test_dataset = RetinaVesselDataset(
        image_dir=test_image_dir,
        is_train=False,
        image_size=512
    )

    test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False, num_workers=2)
    print(f"æµ‹è¯•é›†å¤§å°: {len(test_dataset)}")

    print("\n" + "=" * 60)
    print("ç¬¬4æ­¥ï¼šè¿›è¡Œé¢„æµ‹")
    print("=" * 60)

    predictions = predict_test_set(model, test_loader, threshold=0.5)

    print("\n" + "=" * 60)
    print("ç¬¬5æ­¥ï¼šä¿å­˜ç»“æœ")
    print("=" * 60)

    save_predictions_to_csv(predictions, output_csv)

    print("\n" + "=" * 60)
    print("å®Œæˆï¼")
    print("=" * 60)

if __name__ == "__main__":
    print("å¼€å§‹æ‰§è¡Œè¡€ç®¡åˆ†å‰²è®­ç»ƒä¸é¢„æµ‹è„šæœ¬ï¼ˆé›†æˆCLAHE+Gamma+Dropoutï¼‰...")

    torch.manual_seed(42)
    np.random.seed(42)

    try:
        main()
    except Exception as e:
        print(f"\né”™è¯¯: {e}")
        print("=" * 60)
        print("è¯·æ£€æŸ¥è·¯å¾„å’Œç¯å¢ƒé…ç½®ï¼")
        print("=" * 60)
