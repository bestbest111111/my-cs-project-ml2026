import os
import cv2
import numpy as np
import pandas as pd
import logging
import time
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.metrics import mean_squared_error
import warnings
warnings.filterwarnings('ignore')

# 配置日志
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('model_training.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# 设置路径
base_path = 'D:/Machine_learning/task4/detection'
train_img_path = os.path.join(base_path, 'train')
test_img_path = os.path.join(base_path, 'test')
train_csv_path = os.path.join(base_path, 'fovea_localization_train_GT.csv')
sample_submission_path = os.path.join(base_path, 'sample_submission.csv')

def extract_deep_features(image_path):
    """从图像中提取优化的深度特征"""
    try:
        img = cv2.imread(image_path)
        if img is None:
            logger.warning(f"无法读取图像: {image_path}")
            return None
        
        # 转换为灰度图
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        h, w = gray.shape
        
        # 检查图像尺寸
        if h < 10 or w < 10:
            logger.warning(f"图像尺寸过小: {h}x{w} - {image_path}")
            return None
        
        # 预计算常用值
        channels = [gray, *cv2.split(img)]  # gray, r, g, b
        features = []
        
        # 1. 优化的统计特征计算
        for channel in channels:
            features.extend([
                np.mean(channel), np.std(channel), 
                np.min(channel), np.max(channel), np.median(channel)
            ])
        
        # 2. 优化的直方图特征（减少bins数量）
        for channel in channels:
            hist = cv2.calcHist([channel], [0], None, [16], [0, 256])  # 进一步减少bins
            features.extend(hist.flatten())
        
        # 3. 图像尺寸和形状特征
        features.extend([h, w, h * w, h / w if w > 0 else 0])  # 添加宽高比
        
        # 4. 优化的边缘检测特征
        edges = cv2.Canny(gray, 100, 200)
        features.extend([np.sum(edges > 0), np.mean(edges)])
        
        # 5. 优化的网格特征（减少网格数量）
        grid_size = 4  # 从8x8减少到4x4
        grid_h, grid_w = max(h // grid_size, 1), max(w // grid_size, 1)
        
        for i in range(grid_size):
            for j in range(grid_size):
                start_h = i * grid_h
                end_h = min((i + 1) * grid_h, h)
                start_w = j * grid_w
                end_w = min((j + 1) * grid_w, w)
                
                if end_h > start_h and end_w > start_w:
                    region = gray[start_h:end_h, start_w:end_w]
                    features.extend([np.mean(region), np.std(region)])
                else:
                    features.extend([0, 0])  # 无效区域填充
        
        # 6. 关键图像矩特征（只保留重要矩）
        moments = cv2.moments(gray)
        features.extend([
            moments['m00'], moments['m01'], moments['m10'],
            moments['m02'], moments['m20']
        ])
        
        # 7. 简化的纹理特征
        if h > 1 and w > 1:
            glcm = cv2.calcHist([gray], [0], None, [64], [0, 256])  # 减少bins
            features.extend(glcm.flatten()[:8])  # 只取前8个特征
        
        # 8. 优化的二值化特征
        _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        features.append(np.sum(binary > 0))
        
        feature_array = np.array(features, dtype=np.float32)  # 使用float32节省内存
        
        # 检查特征是否有效
        if np.any(np.isnan(feature_array)) or np.any(np.isinf(feature_array)):
            logger.warning(f"特征包含无效值: {image_path}")
            return None
            
        return feature_array
        
    except Exception as e:
        logger.error(f"特征提取错误 {image_path}: {str(e)}")
        return None

def prepare_training_data():
    """准备训练数据（优化版本）"""
    df = pd.read_csv(train_csv_path)
    
    # 预分配数组大小
    n_samples = len(df)
    X = np.zeros((n_samples, 200), dtype=np.float32)  # 预分配内存
    y_x = np.zeros(n_samples, dtype=np.float32)
    y_y = np.zeros(n_samples, dtype=np.float32)
    
    valid_samples = 0
    
    for idx, row in df.iterrows():
        img_id = int(row['data'])
        img_filename = f"{img_id:04d}.jpg"
        img_path = os.path.join(train_img_path, img_filename)
        
        features = extract_deep_features(img_path)
        if features is not None:
            # 确保特征数量一致
            if len(features) <= X.shape[1]:
                X[valid_samples, :len(features)] = features
                y_x[valid_samples] = row['Fovea_X']
                y_y[valid_samples] = row['Fovea_Y']
                valid_samples += 1
            else:
                print(f"警告: 特征数量不匹配 {img_filename}")
        else:
            print(f"警告: 无法处理训练图像 {img_filename}")
    
    # 只返回有效样本
    return X[:valid_samples], y_x[:valid_samples], y_y[:valid_samples]

def prepare_test_data():
    """准备测试数据（优化版本）"""
    test_ids = list(range(81, 101))  # 测试集编号从81到100
    n_samples = len(test_ids)
    
    # 预分配内存
    X_test = np.zeros((n_samples, 200), dtype=np.float32)
    valid_samples = 0
    valid_test_ids = []
    
    for i, img_id in enumerate(test_ids):
        img_filename = f"{img_id:04d}.jpg"
        img_path = os.path.join(test_img_path, img_filename)
        
        features = extract_deep_features(img_path)
        if features is not None and len(features) <= X_test.shape[1]:
            X_test[valid_samples, :len(features)] = features
            valid_test_ids.append(img_id)
            valid_samples += 1
        else:
            print(f"警告: 无法处理测试图像 {img_filename}")
    
    return X_test[:valid_samples], valid_test_ids

def evaluate_cross_validation_rmse(X, y_x, y_y, model_params, cv_folds=5):
    """执行交叉验证并计算RMSE"""
    logger.info(f"开始{cv_folds}折交叉验证评估...")
    
    # 创建模型
    model_x = GradientBoostingRegressor(**model_params)
    model_y = GradientBoostingRegressor(**model_params)
    
    # 执行交叉验证（使用负MSE，然后转换为RMSE）
    cv_scores_x = cross_val_score(model_x, X, y_x, cv=cv_folds, 
                                 scoring='neg_mean_squared_error')
    cv_scores_y = cross_val_score(model_y, X, y_y, cv=cv_folds,
                                 scoring='neg_mean_squared_error')
    
    # 转换为RMSE
    cv_rmse_x = np.sqrt(-cv_scores_x)
    cv_rmse_y = np.sqrt(-cv_scores_y)
    
    # 计算统计信息
    mean_rmse_x = np.mean(cv_rmse_x)
    std_rmse_x = np.std(cv_rmse_x)
    mean_rmse_y = np.mean(cv_rmse_y)
    std_rmse_y = np.std(cv_rmse_y)
    
    logger.info(f"交叉验证RMSE结果:")
    logger.info(f"  X坐标: {cv_rmse_x}")
    logger.info(f"  Y坐标: {cv_rmse_y}")
    logger.info(f"  X坐标平均RMSE: {mean_rmse_x:.2f} (±{std_rmse_x:.2f})")
    logger.info(f"  Y坐标平均RMSE: {mean_rmse_y:.2f} (±{std_rmse_y:.2f})")
    
    return mean_rmse_x, std_rmse_x, mean_rmse_y, std_rmse_y

def main():
    start_time = time.time()
    logger.info("开始模型训练流程...")
    
    try:
        logger.info("准备训练数据...")
        X, y_x, y_y = prepare_training_data()
        logger.info(f"训练数据形状: X={X.shape}, y_x={y_x.shape}, y_y={y_y.shape}")
        
        if len(X) == 0:
            logger.error("错误: 没有有效的训练数据")
            return
        
        # 优化数据分割
        X_train, X_val, y_train_x, y_val_x, y_train_y, y_val_y = train_test_split(
            X, y_x, y_y, test_size=0.15, random_state=42, stratify=None)
        
        logger.info(f"训练集: {X_train.shape[0]} 样本, 验证集: {X_val.shape[0]} 样本")
        
        # 优化的模型参数
        gb_params = {
            'n_estimators': 300,  # 减少树的数量
            'learning_rate': 0.1,  # 提高学习率
            'max_depth': 6,       # 减少深度防止过拟合
            'min_samples_split': 8,
            'min_samples_leaf': 4,
            'subsample': 0.9,
            'random_state': 42,
            'verbose': 1
        }
        
        # 执行交叉验证评估
        cv_mean_rmse_x, cv_std_rmse_x, cv_mean_rmse_y, cv_std_rmse_y = evaluate_cross_validation_rmse(
            X, y_x, y_y, gb_params, cv_folds=5
        )
        
        logger.info("训练X坐标Gradient Boosting回归模型...")
        model_x = GradientBoostingRegressor(**gb_params)
        model_x.fit(X_train, y_train_x)
        
        logger.info("训练Y坐标Gradient Boosting回归模型...")
        model_y = GradientBoostingRegressor(**gb_params)
        model_y.fit(X_train, y_train_y)
        
        # 验证集评估
        val_pred_x = model_x.predict(X_val)
        val_pred_y = model_y.predict(X_val)
        
        mse_x = mean_squared_error(y_val_x, val_pred_x)
        mse_y = mean_squared_error(y_val_y, val_pred_y)
        rmse_x = np.sqrt(mse_x)
        rmse_y = np.sqrt(mse_y)
        
        logger.info(f"验证集性能 - X坐标: MSE={mse_x:.2f}, RMSE={rmse_x:.2f}")
        logger.info(f"验证集性能 - Y坐标: MSE={mse_y:.2f}, RMSE={rmse_y:.2f}")
        
        # 使用完整数据重新训练最终模型
        logger.info("使用完整数据训练最终模型...")
        final_model_x = GradientBoostingRegressor(**gb_params)
        final_model_y = GradientBoostingRegressor(**gb_params)
        
        final_model_x.fit(X, y_x)
        final_model_y.fit(X, y_y)
        
        logger.info("准备测试数据...")
        X_test, test_ids = prepare_test_data()
        logger.info(f"测试数据形状: X_test={X_test.shape}")
        
        if len(X_test) == 0:
            logger.error("错误: 没有有效的测试数据")
            return
        
        logger.info("预测测试集...")
        test_pred_x = final_model_x.predict(X_test)
        test_pred_y = final_model_y.predict(X_test)
        
        # 优化提交文件处理
        submission_df = pd.read_csv(sample_submission_path)
        
        # 使用向量化操作提高效率
        for img_id, pred_x, pred_y in zip(test_ids, test_pred_x, test_pred_y):
            x_key = f"{img_id}_Fovea_X"
            y_key = f"{img_id}_Fovea_Y"
            
            # 使用布尔索引提高效率
            submission_df.loc[submission_df['ImageID'] == x_key, 'value'] = pred_x
            submission_df.loc[submission_df['ImageID'] == y_key, 'value'] = pred_y
        
        # 保存提交文件
        output_file = 'submission_gb_optimized.csv'
        submission_df.to_csv(output_file, index=False)
        
        # 性能统计
        elapsed_time = time.time() - start_time
        
        # 计算最终模型的RMSE
        final_val_pred_x = final_model_x.predict(X_val)
        final_val_pred_y = final_model_y.predict(X_val)
        final_rmse_x = np.sqrt(mean_squared_error(y_val_x, final_val_pred_x))
        final_rmse_y = np.sqrt(mean_squared_error(y_val_y, final_val_pred_y))
        
        logger.info("=" * 60)
        logger.info("RMSE性能总结报告")
        logger.info("=" * 60)
        logger.info(f"最终模型验证集性能:")
        logger.info(f"  X坐标: RMSE = {final_rmse_x:.2f}")
        logger.info(f"  Y坐标: RMSE = {final_rmse_y:.2f}")
        logger.info(f"交叉验证平均性能:")
        logger.info(f"  X坐标: RMSE = {cv_mean_rmse_x:.2f} (±{cv_std_rmse_x:.2f})")
        logger.info(f"  Y坐标: RMSE = {cv_mean_rmse_y:.2f} (±{cv_std_rmse_y:.2f})")
        logger.info(f"总运行时间: {elapsed_time:.2f} 秒")
        logger.info(f"提交文件已保存为: {output_file}")
        logger.info("=" * 60)
        
        # 显示部分结果
        print("\n部分预测结果:")
        print(submission_df.head(8))
        
    except Exception as e:
        logger.error(f"训练流程出错: {str(e)}")
        raise

if __name__ == "__main__":
    main()
