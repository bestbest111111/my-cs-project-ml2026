# emotion_recognition.py
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import transforms, models, datasets
from torch.utils.data import Dataset, DataLoader
import os
import glob
from PIL import Image
import numpy as np
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix, classification_report
import pandas as pd
from tqdm import tqdm
import warnings
warnings.filterwarnings('ignore')

# 设置随机种子保证可重复性
def set_seed(seed=42):
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    np.random.seed(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

set_seed(42)

# ==================== 1. 数据集类定义 ====================
class EmotionDataset(Dataset):
    """自定义情绪识别数据集类"""
    def __init__(self, data_dir, transform=None, mode='train'):
        self.data_dir = data_dir
        self.transform = transform
        self.mode = mode
        self.classes = ['Angry', 'Fear', 'Happy', 'Neutral', 'Sad', 'Surprise']
        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}
        self.idx_to_class = {idx: cls for cls, idx in self.class_to_idx.items()}
        
        # 如果是训练模式，加载带标签的数据
        if mode == 'train':
            self.images = []
            self.labels = []
            
            print("正在加载训练数据...")
            for class_name in self.classes:
                class_dir = os.path.join(data_dir, class_name)
                if os.path.exists(class_dir):
                    # 支持多种图片格式
                    image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.JPG', '*.JPEG', '*.PNG']
                    image_files = []
                    for ext in image_extensions:
                        image_files.extend(glob.glob(os.path.join(class_dir, ext)))
                    
                    for img_path in image_files:
                        self.images.append(img_path)
                        self.labels.append(self.class_to_idx[class_name])
                    
                    print(f"  {class_name}: {len(image_files)} 张图片")
        # 测试模式，只有图片
        else:
            self.images = []
            image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp']
            for ext in image_extensions:
                self.images.extend(glob.glob(os.path.join(data_dir, ext)))
            self.labels = None
            print(f"测试集: {len(self.images)} 张图片")
    
    def __len__(self):
        return len(self.images)
    
    def __getitem__(self, idx):
        img_path = self.images[idx]
        
        try:
            image = Image.open(img_path).convert('RGB')
        except:
            # 如果图片损坏，返回黑色图片
            print(f"警告: 无法加载图片 {img_path}")
            image = Image.new('RGB', (48, 48), color='black')
        
        if self.transform:
            image = self.transform(image)
        
        if self.mode == 'train' and self.labels is not None:
            return image, self.labels[idx]
        else:
            # 返回文件名用于识别
            filename = os.path.basename(img_path)
            return image, filename

# ==================== 2. 模型定义 ====================
class EnhancedEmotionCNN(nn.Module):
    """增强的CNN模型，使用注意力机制"""
    def __init__(self, num_classes=6):
        super(EnhancedEmotionCNN, self).__init__()
        
        # 卷积层块1
        self.conv_block1 = nn.Sequential(
            nn.Conv2d(3, 64, kernel_size=3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 64, kernel_size=3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2, 2),
            nn.Dropout(0.25)
        )
        
        # 卷积层块2
        self.conv_block2 = nn.Sequential(
            nn.Conv2d(64, 128, kernel_size=3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.Conv2d(128, 128, kernel_size=3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2, 2),
            nn.Dropout(0.25)
        )
        
        # 卷积层块3
        self.conv_block3 = nn.Sequential(
            nn.Conv2d(128, 256, kernel_size=3, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            nn.Conv2d(256, 256, kernel_size=3, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2, 2),
            nn.Dropout(0.25)
        )
        
        # 卷积层块4
        self.conv_block4 = nn.Sequential(
            nn.Conv2d(256, 512, kernel_size=3, padding=1),
            nn.BatchNorm2d(512),
            nn.ReLU(inplace=True),
            nn.Conv2d(512, 512, kernel_size=3, padding=1),
            nn.BatchNorm2d(512),
            nn.ReLU(inplace=True),
            nn.AdaptiveAvgPool2d((1, 1))
        )
        
        # 通道注意力模块
        self.channel_attention = nn.Sequential(
            nn.Linear(512, 512 // 16),
            nn.ReLU(inplace=True),
            nn.Linear(512 // 16, 512),
            nn.Sigmoid()
        )
        
        # 全连接层
        self.fc = nn.Sequential(
            nn.Dropout(0.5),
            nn.Linear(512, 256),
            nn.ReLU(inplace=True),
            nn.Dropout(0.3),
            nn.Linear(256, num_classes)
        )
        
    def forward(self, x):
        x = self.conv_block1(x)
        x = self.conv_block2(x)
        x = self.conv_block3(x)
        x = self.conv_block4(x)
        
        # 应用通道注意力
        batch_size = x.size(0)
        x_pooled = x.view(batch_size, -1)
        channel_weights = self.channel_attention(x_pooled).view(batch_size, 512, 1, 1)
        x = x * channel_weights
        
        x = x.view(x.size(0), -1)
        x = self.fc(x)
        return x

# ==================== 3. 训练函数 ====================
class EmotionTrainer:
    """训练器类"""
    def __init__(self, model, device='cuda' if torch.cuda.is_available() else 'cpu'):
        self.model = model.to(device)
        self.device = device
        self.criterion = nn.CrossEntropyLoss()
        self.optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)
        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(
            self.optimizer, mode='min', factor=0.5, patience=5, verbose=True
        )
        
    def train_epoch(self, train_loader):
        self.model.train()
        running_loss = 0.0
        correct = 0
        total = 0
        
        pbar = tqdm(train_loader, desc="训练中")
        for batch_idx, (inputs, labels) in enumerate(pbar):
            inputs, labels = inputs.to(self.device), labels.to(self.device)
            
            self.optimizer.zero_grad()
            outputs = self.model(inputs)
            loss = self.criterion(outputs, labels)
            loss.backward()
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
            self.optimizer.step()
            
            running_loss += loss.item()
            _, predicted = outputs.max(1)
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()
            
            pbar.set_postfix({
                'Loss': running_loss/(batch_idx+1),
                'Acc': 100.*correct/total
            })
        
        epoch_loss = running_loss / len(train_loader)
        epoch_acc = 100. * correct / total
        return epoch_loss, epoch_acc
    
    def validate(self, val_loader):
        self.model.eval()
        running_loss = 0.0
        correct = 0
        total = 0
        all_preds = []
        all_labels = []
        
        with torch.no_grad():
            pbar = tqdm(val_loader, desc="验证中")
            for inputs, labels in pbar:
                inputs, labels = inputs.to(self.device), labels.to(self.device)
                
                outputs = self.model(inputs)
                loss = self.criterion(outputs, labels)
                
                running_loss += loss.item()
                _, predicted = outputs.max(1)
                total += labels.size(0)
                correct += predicted.eq(labels).sum().item()
                
                all_preds.extend(predicted.cpu().numpy())
                all_labels.extend(labels.cpu().numpy())
                
                pbar.set_postfix({
                    'Loss': running_loss/len(pbar),
                    'Acc': 100.*correct/total
                })
        
        epoch_loss = running_loss / len(val_loader)
        epoch_acc = 100. * correct / total
        return epoch_loss, epoch_acc, all_preds, all_labels

# ==================== 4. 可视化函数 ====================
def plot_training_history(train_losses, val_losses, train_accs, val_accs):
    """绘制训练历史"""
    fig, axes = plt.subplots(1, 2, figsize=(15, 5))
    
    # 绘制损失曲线
    axes[0].plot(train_losses, label='训练损失', linewidth=2)
    axes[0].plot(val_losses, label='验证损失', linewidth=2)
    axes[0].set_xlabel('Epoch')
    axes[0].set_ylabel('损失')
    axes[0].set_title('训练和验证损失曲线')
    axes[0].legend()
    axes[0].grid(True, alpha=0.3)
    
    # 绘制准确率曲线
    axes[1].plot(train_accs, label='训练准确率', linewidth=2)
    axes[1].plot(val_accs, label='验证准确率', linewidth=2)
    axes[1].set_xlabel('Epoch')
    axes[1].set_ylabel('准确率 (%)')
    axes[1].set_title('训练和验证准确率曲线')
    axes[1].legend()
    axes[1].grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('training_history.png', dpi=300, bbox_inches='tight')
    plt.show()

def plot_confusion_matrix(all_labels, all_preds, class_names):
    """绘制混淆矩阵"""
    cm = confusion_matrix(all_labels, all_preds)
    
    plt.figure(figsize=(10, 8))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=class_names, yticklabels=class_names)
    plt.title('混淆矩阵')
    plt.ylabel('真实标签')
    plt.xlabel('预测标签')
    plt.tight_layout()
    plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    # 打印分类报告
    print("\n分类报告:")
    print(classification_report(all_labels, all_preds, target_names=class_names))

# ==================== 5. 主训练函数 ====================
def train_model(train_dir, val_ratio=0.2, batch_size=32, epochs=50):
    """主训练函数"""
    
    # 数据预处理
    train_transform = transforms.Compose([
        transforms.Resize((128, 128)),
        transforms.RandomHorizontalFlip(p=0.5),
        transforms.RandomRotation(10),
        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                           std=[0.229, 0.224, 0.225])
    ])
    
    val_transform = transforms.Compose([
        transforms.Resize((128, 128)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                           std=[0.229, 0.224, 0.225])
    ])
    
    # 加载完整训练数据集
    full_dataset = EmotionDataset(train_dir, transform=train_transform, mode='train')
    
    # 划分训练集和验证集
    train_size = int((1 - val_ratio) * len(full_dataset))
    val_size = len(full_dataset) - train_size
    train_dataset, val_dataset = torch.utils.data.random_split(
        full_dataset, [train_size, val_size]
    )
    
    # 设置验证集的变换
    val_dataset.dataset.transform = val_transform
    
    # 创建数据加载器
    train_loader = DataLoader(train_dataset, batch_size=batch_size,
                            shuffle=True, num_workers=4, pin_memory=True)
    val_loader = DataLoader(val_dataset, batch_size=batch_size,
                          shuffle=False, num_workers=4, pin_memory=True)
    
    print(f"\n数据统计:")
    print(f"训练集: {len(train_dataset)} 张图片")
    print(f"验证集: {len(val_dataset)} 张图片")
    
    # 初始化模型和训练器
    model = EnhancedEmotionCNN(num_classes=6)
    trainer = EmotionTrainer(model)
    
    print(f"\n模型参数总数: {sum(p.numel() for p in model.parameters()):,}")
    print(f"可训练参数: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}")
    
    # 训练循环
    best_val_acc = 0
    train_losses, val_losses = [], []
    train_accs, val_accs = [], []
    
    print("\n开始训练...")
    for epoch in range(epochs):
        print(f"\nEpoch {epoch+1}/{epochs}")
        print("-" * 50)
        
        # 训练
        train_loss, train_acc = trainer.train_epoch(train_loader)
        train_losses.append(train_loss)
        train_accs.append(train_acc)
        
        # 验证
        val_loss, val_acc, val_preds, val_labels = trainer.validate(val_loader)
        val_losses.append(val_loss)
        val_accs.append(val_acc)
        
        # 学习率调整
        trainer.scheduler.step(val_loss)
        
        # 保存最佳模型
        if val_acc > best_val_acc:
            best_val_acc = val_acc
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': trainer.optimizer.state_dict(),
                'val_acc': val_acc,
                'train_acc': train_acc,
            }, 'best_emotion_model.pth')
            print(f"保存最佳模型，验证准确率: {val_acc:.2f}%")
        
        print(f"训练损失: {train_loss:.4f}, 训练准确率: {train_acc:.2f}%")
        print(f"验证损失: {val_loss:.4f}, 验证准确率: {val_acc:.2f}%")
    
    # 绘制训练历史
    plot_training_history(train_losses, val_losses, train_accs, val_accs)
    
    # 绘制混淆矩阵
    print("\n正在生成混淆矩阵...")
    plot_confusion_matrix(val_labels, val_preds, full_dataset.classes)
    
    return model, best_val_acc

# ==================== 6. 预测函数 ====================
class EmotionPredictor:
    """情绪预测器"""
    def __init__(self, model_path='best_emotion_model.pth', device=None):
        if device is None:
            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        else:
            self.device = device
        
        # 加载模型
        self.model = EnhancedEmotionCNN(num_classes=6)
        checkpoint = torch.load(model_path, map_location=self.device)
        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.model.to(self.device)
        self.model.eval()
        
        # 类别映射
        self.classes = ['Angry', 'Fear', 'Happy', 'Neutral', 'Sad', 'Surprise']
        
        # 预处理
        self.transform = transforms.Compose([
            transforms.Resize((128, 128)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406],
                              std=[0.229, 0.224, 0.225])
        ])
    
    def predict_single(self, image_path):
        """预测单张图片"""
        try:
            image = Image.open(image_path).convert('RGB')
            image_tensor = self.transform(image).unsqueeze(0).to(self.device)
            
            with torch.no_grad():
                outputs = self.model(image_tensor)
                probabilities = F.softmax(outputs, dim=1)
                confidence, predicted = torch.max(probabilities, 1)
                
                emotion = self.classes[predicted.item()]
                confidence = confidence.item() * 100
                
            return {
                'emotion': emotion,
                'confidence': confidence,
                'probabilities': probabilities.squeeze().cpu().numpy()
            }
        except Exception as e:
            print(f"预测错误 {image_path}: {str(e)}")
            return None
    
    def predict_batch(self, test_dir):
        """批量预测测试集"""
        # 创建测试数据集
        test_dataset = EmotionDataset(test_dir, transform=self.transform, mode='test')
        test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)
        
        results = []
        
        print(f"\n开始批量预测测试集 ({len(test_dataset)} 张图片)...")
        with torch.no_grad():
            pbar = tqdm(test_loader, desc="预测中")
            for images, filenames in pbar:
                images = images.to(self.device)
                outputs = self.model(images)
                probabilities = F.softmax(outputs, dim=1)
                confidences, predictions = torch.max(probabilities, 1)
                
                for i in range(len(filenames)):
                    result = {
                        'filename': filenames[i],
                        'predicted_emotion': self.classes[predictions[i].item()],
                        'confidence': confidences[i].item() * 100
                    }
                    results.append(result)
        
        # 保存结果到CSV
        df = pd.DataFrame(results)
        df.to_csv('emotion_predictions.csv', index=False, encoding='utf-8-sig')
        
        print(f"\n预测完成! 结果已保存到 'emotion_predictions.csv'")
        
        # 显示统计信息
        print("\n情绪分布统计:")
        emotion_counts = df['predicted_emotion'].value_counts()
        for emotion, count in emotion_counts.items():
            percentage = count / len(df) * 100
            print(f"{emotion}: {count} 张 ({percentage:.1f}%)")
        
        return df

# ==================== 7. 示例使用 ====================
def main():
    """主函数示例"""
    
    # 检查数据目录结构
    print("=" * 60)
    print("情绪识别深度学习模型")
    print("=" * 60)
    
    # 假设您的数据目录结构如下：
    # train_data/
    #   ├── Angry/
    #   ├── Fear/
    #   ├── Happy/
    #   ├── Neutral/
    #   ├── Sad/
    #   └── Surprise/
    # test_data/ (仅包含图片，无子文件夹)
    
    train_data_dir = "C:/19429/Downloads/neu-image-emotion-classification.zip/fer_data/fer_data/train"  # 修改为您的训练数据路径
    test_data_dir = "C:/Users/19429/Downloads/neu-image-emotion-classification.zip/fer_data/fer_data/test"    # 修改为您的测试数据路径
    
    # 检查目录是否存在
    if not os.path.exists(train_data_dir):
        print(f"错误: 训练目录 '{train_data_dir}' 不存在!")
        print("请创建以下目录结构:")
        print("train_data/")
        print("  ├── Angry/")
        print("  ├── Fear/")
        print("  ├── Happy/")
        print("  ├── Neutral/")
        print("  ├── Sad/")
        print("  └── Surprise/")
        return
    
    # 步骤1: 训练模型
    print("\n[步骤1] 训练模型")
    print("-" * 40)
    
    # 如果您想训练模型，取消下面的注释
    # model, best_acc = train_model(
    #     train_dir=train_data_dir,
    #     val_ratio=0.2,
    #     batch_size=32,
    #     epochs=30
    # )
    
    # 步骤2: 预测测试集
    print("\n[步骤2] 预测测试集")
    print("-" * 40)
    
    if os.path.exists(test_data_dir):
        # 初始化预测器（假设已经有训练好的模型）
        if os.path.exists('best_emotion_model.pth'):
            predictor = EmotionPredictor('best_emotion_model.pth')
            
            # 批量预测
            results = predictor.predict_batch(test_data_dir)
            
            # 显示前10个结果
            print("\n前10个预测结果:")
            print(results.head(10))
            
            # 示例：预测单张图片
            # 如果测试目录中有图片，选择第一张进行示例
            test_images = glob.glob(os.path.join(test_data_dir, "*.jpg")) + \
                         glob.glob(os.path.join(test_data_dir, "*.png"))
            
            if test_images:
                print("\n单张图片预测示例:")
                single_result = predictor.predict_single(test_images[0])
                if single_result:
                    print(f"图片: {os.path.basename(test_images[0])}")
                    print(f"预测情绪: {single_result['emotion']}")
                    print(f"置信度: {single_result['confidence']:.2f}%")
                    
                    # 显示所有情绪的概率
                    print("\n所有情绪的概率:")
                    for i, emotion in enumerate(predictor.classes):
                        prob = single_result['probabilities'][i] * 100
                        print(f"  {emotion}: {prob:.2f}%")
        else:
            print("未找到训练好的模型。请先训练模型或提供模型路径。")
    else:
        print(f"测试目录 '{test_data_dir}' 不存在，跳过预测步骤。")
    
    print("\n" + "=" * 60)
    print("程序执行完成!")
    print("=" * 60)

# ==================== 8. 快速使用函数 ====================
def quick_train_and_predict(train_dir, test_dir, epochs=30):
    """快速训练和预测函数"""
    
    # 1. 训练模型
    print("正在训练模型...")
    model, best_acc = train_model(
        train_dir=train_dir,
        val_ratio=0.2,
        batch_size=32,
        epochs=epochs
    )
    
    # 2. 预测测试集
    print("\n正在预测测试集...")
    predictor = EmotionPredictor('best_emotion_model.pth')
    results = predictor.predict_batch(test_dir)
    
    return results

def visualize_sample_predictions(test_dir, num_samples=9):
    """可视化样本预测结果"""
    if not os.path.exists('best_emotion_model.pth'):
        print("请先训练模型!")
        return
    
    predictor = EmotionPredictor()
    
    # 获取测试图片
    image_paths = []
    for ext in ['*.jpg', '*.jpeg', '*.png']:
        image_paths.extend(glob.glob(os.path.join(test_dir, ext)))
    
    if not image_paths:
        print("测试目录中没有找到图片!")
        return
    
    # 随机选择样本
    if len(image_paths) > num_samples:
        indices = np.random.choice(len(image_paths), num_samples, replace=False)
        sample_paths = [image_paths[i] for i in indices]
    else:
        sample_paths = image_paths
    
    # 创建可视化
    fig, axes = plt.subplots(3, 3, figsize=(15, 15))
    axes = axes.ravel()
    
    for idx, img_path in enumerate(sample_paths[:num_samples]):
        result = predictor.predict_single(img_path)
        
        if result:
            img = Image.open(img_path)
            axes[idx].imshow(img)
            axes[idx].set_title(
                f"{result['emotion']}\nConfidence: {result['confidence']:.1f}%",
                fontsize=12, fontweight='bold'
            )
            axes[idx].axis('off')
    
    plt.tight_layout()
    plt.savefig('sample_predictions.png', dpi=300, bbox_inches='tight')
    plt.show()

# ==================== 9. 运行主程序 ====================
if __name__ == "__main__":
    # 简单示例：直接运行主函数
    main()
    
    # 或者使用快速函数
    # results = quick_train_and_predict("train_data", "test_data", epochs=30)
    
    # 或者只训练
    # model, best_acc = train_model("train_data", epochs=30)
    
    # 或者只预测（如果有训练好的模型）
    # predictor = EmotionPredictor()
    # results = predictor.predict_batch("test_data")
